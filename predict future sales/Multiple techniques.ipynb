{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading data into the file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/items.csv')                            \nprint(items.shape, items.dtypes)\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\nprint(sales_train.shape, sales_train.dtypes)\nsales_train.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['date'] = pd.to_datetime(sales_train.date, format='%d.%m.%Y')\nsales_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv')\nprint(item_categories.shape, item_categories.dtypes)\nitem_categories.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv')\nprint(test.shape, test.dtypes)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/shops.csv')\nprint(shops.shape, shops.dtypes)\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv')\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* With these we get a basic insight of the datatypes and we resolve any mismatch in the dtype and the column content. \n* We also see that there is no missing values in the data from analysing the given data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"category = items['item_category_id'].value_counts().to_frame()\ncategory.rename(columns={'item_category_id': 'value_counts'}, inplace=True)\ncategory.index.name = 'item_category_id'\ncategory.sort_values(by='item_category_id', inplace = True)\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x='item_category_id', y='value_counts', data =category.reset_index())\nplt.xlabel('Item Category Id')\nplt.ylabel('Number of items')\nplt.ylim(0, 2500)\nplt.title('number of items in each category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month = pd.DataFrame(sales_train.groupby(['date_block_num']).sum().item_cnt_day).reset_index()\nmonth.rename(columns={'item_cnt_day':'items_sold'}, inplace=True)\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x ='date_block_num', y='items_sold', data=month.reset_index());\nplt.title('Sum of sales per month')\nplt.xlabel('Date block Number')\nplt.ylabel('Number of items sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month = pd.DataFrame(sales_train.groupby(['date_block_num']).sum().item_cnt_day).reset_index()\nmonth.rename(columns={'item_cnt_day':'items_sold'}, inplace=True)\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x ='date_block_num', y='items_sold', data=month.reset_index());\nplt.title('Sum of sales per month')\nplt.xlabel('Date block Number')\nplt.ylabel('Number of items sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_shop = pd.DataFrame(sales_train.groupby(['shop_id']).sum().item_cnt_day).reset_index()\nsales_shop.rename(columns={'item_cnt_day':'shop_sales'}, inplace=True)\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x ='shop_id', y='shop_sales', data=sales_shop)\nplt.title('Sales per shop')\nplt.xlabel('Shop id')\nplt.ylabel('Sales Sum')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_item = pd.DataFrame(sales_train.groupby(['item_id']).sum().item_cnt_day).reset_index()\nsales_item.rename(columns={'item_cnt_day':'item_sales'}, inplace=True)\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x ='item_id', y='item_sales', data=sales_item)\nplt.title('Sales per item')\nplt.xlabel('item id')\nplt.ylabel('Sales Sum')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cat = sales_train.merge(items, on='item_id')\nitem_cat = item_cat.groupby('item_category_id').item_cnt_day.sum()\n\nplt.figure(figsize=(16, 14))\nsns.barplot(x ='item_category_id', y='item_cnt_day', data=item_cat.reset_index())\nplt.xlabel('Item Category id')\nplt.ylabel('Item Count')\nplt.title('Sales per item category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['day'] = sales_train['date'].dt.day\nsales_train['month'] = sales_train['date'].dt.month\nsales_train['year'] = sales_train['date'].dt.year\nsales_train['week'] = sales_train['date'].dt.week\nsales_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 14))\nsns.countplot(sales_train['day'])\nplt.title('Busiest days for the shops')\nplt.xlabel('Days')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 14))\nsns.countplot(sales_train['month'])\nplt.title('Busiest month for the shops')\nplt.xlabel('Month')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['revenue'] = sales_train['item_price'] * sales_train['item_cnt_day']\n\nplt.figure(figsize=(16, 14))\nsns.distplot(sales_train['revenue'], color = 'blue')\nplt.title('Distribution of Revenue')\nplt.xlabel('Range of Revenue')\nplt.ylabel('Revenue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.boxplot(x=sales_train.item_cnt_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=sales_train.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train[sales_train.item_price<100000]\nsales_train = sales_train[sales_train.item_cnt_day<1001]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating Required Features Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.columns, sales_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making a dataset with only monthly sales data\ndataset = sales_train.groupby([sales_train['date'].apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).sum().reset_index()\ndataset.head(), dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# specifying the important attributes which we want to add to the data\ndataset = dataset[['date','item_id','shop_id','item_cnt_day']]\n\n# at last we can select the specific attributes from the dataset which are important \ndataset = dataset.pivot_table(index=['item_id','shop_id'], columns = 'date', values = 'item_cnt_day', fill_value = 0).reset_index()\ndataset.head(), dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's merge the monthly sales data prepared to the test data set\ntestset = pd.merge(test, dataset, on = ['item_id', 'shop_id'], how = 'left')\n\n# filling the empty values found in the dataset\ntestset.fillna(0, inplace = True)\n\n# checking the dataset\ntestset.head(), testset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now let's create the actual training data\n\nx = dataset.drop(['2015-10', 'item_id', 'shop_id'], axis = 1)\ny = dataset['2015-10']\n\nx_train, x_val, y_train , y_val = train_test_split(x, y, test_size = 0.2)\n# deleting the first column so that it can predict the future sales data\nx_test = testset.drop(['2013-01', 'item_id', 'shop_id', 'ID'], axis = 1)\n\n# checking the shapes of the datasets\nprint(\"Shape of x_train :\", x_train.shape)\nprint(\"Shape of x_test :\", x_test.shape)\nprint(\"Shape of y_train :\", y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Miltiple Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfeature_scaler = StandardScaler()\ndataset = feature_scaler.fit_transform(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nlm = LinearRegression()\nall_accuracies = -1 * cross_val_score(estimator=lm, X=x_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\nprint(np.sqrt(all_accuracies.mean()))\nlm.fit(x_train, y_train)\nyx = lm.predict(x_train)\nnp.sqrt(mean_squared_error(y_train, yx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_accuracies = cross_val_score(estimator=lm, X=x_train, y=y_train, cv=5)\nprint(all_accuracies.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.fit(x_train, y_train)\nyhat = lm.predict(x_test).clip(0, 20)\nyhat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'\npreds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Polynomial Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\npoly = PolynomialFeatures(degree=2)\ntrain_x_poly = poly.fit_transform(x_train)\n\nclf = linear_model.LinearRegression()\nall_accuracies = -1 * cross_val_score(estimator=clf, X=train_x_poly, y=y_train, cv=5, scoring='neg_mean_squared_error')\nprint(np.sqrt(all_accuracies.mean()))\ntrain_y_ = clf.fit(train_x_poly, y_train)\nyx = train_y_.predict(train_x_poly)\nnp.sqrt(mean_squared_error(y_train, yx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_poly = poly.fit_transform(x_test)\nyhat = train_y_.predict(x_test_poly).clip(0, 20)\nyhat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Ridge Regression (L2 regularization)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\nRidgeModel = Ridge(alpha = 0.1)\nfrom sklearn.metrics import mean_squared_error\npoly = PolynomialFeatures(degree=2)\ntrain_x_poly = poly.fit_transform(x_train)\nx_test_poly = poly.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RidgeModel.fit(train_x_poly, y_train)\nyhat = RidgeModel.predict(x_test_poly)\ny_tr = RidgeModel.predict(train_x_poly)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'\npreds.to_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RidgeModel.fit(x_train, y_train)\nyhat = RidgeModel.predict(x_test)\ny_tr = RidgeModel.predict(x_train)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Lasso Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nls = Lasso(alpha = 0.1)\nls.fit(x_train, y_train)\nyhat = ls.predict(x_test)\ny_tr = ls.predict(x_train)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'\npreds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Elastic Net Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nen = ElasticNet()\nen.fit(x_train, y_train)\nyhat = en.predict(x_test)\ny_tr = en.predict(x_train)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'\npreds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Principal Component Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 1)\npca.fit(x_train, y_train)\npca.score(x_train)\npca.score(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nsv = svm.SVC(kernel='rbf')\nsv.fit(x_train, y_train) \nyhat = sv.predict(x_test)\ny_tr = sv.predict(x_train)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Using Random Forest Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor()\nrf.fit(x_train, y_train)\nyhat = rf.predict(x_test).clip(0, 20)\ny_tr = rf.predict(x_train)\nmse = mean_squared_error(y_train, y_tr)\nnp.sqrt(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = rf.predict(x_test).clip(0, 20)\npreds = pd.DataFrame(yhat, columns=['item_cnt_month'])\npreds.index.name = 'ID'\npreds.to_csv('/kaggle/working/randomforest.csv')\npreds","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}